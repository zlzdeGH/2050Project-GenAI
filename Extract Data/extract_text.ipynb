{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb254eac",
   "metadata": {},
   "source": [
    "## 1. doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f9dc0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping .doc file '7Y6H93I4L6F5bcplrUpPbf5AjQcypbJfrevTSiNf.doc' as 'pywin32' is not available on this system.\n",
      "Please manually save it as .docx or .pdf to analyze.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys \n",
    "from docx import Document\n",
    "import pdfplumber\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    try:\n",
    "        import win32com.client as win32\n",
    "    except ImportError:\n",
    "        print(\"Warning: The 'pywin32' library is not installed. .doc files cannot be processed.\")\n",
    "        print(\"To enable .doc support on Windows, run: pip install pywin32\")\n",
    "        win32 = None\n",
    "else:\n",
    "    win32 = None\n",
    "    \n",
    "def extract_paragraphs_from_doc(doc_path):\n",
    "    \"\"\"\n",
    "    Extracts paragraphs from a .doc file using MS Word automation (Windows only).\n",
    "    \"\"\"\n",
    "    if not win32:\n",
    "        print(f\"Skipping .doc file '{os.path.basename(doc_path)}' as 'pywin32' is not available on this system.\")\n",
    "        print(\"Please manually save it as .docx or .pdf to analyze.\")\n",
    "        return []\n",
    "    \n",
    "    word = None\n",
    "    doc = None\n",
    "    try:\n",
    "        word = win32.Dispatch(\"Word.Application\")\n",
    "        word.Visible = False\n",
    "        # Get the full absolute path, which COM objects often require\n",
    "        abs_path = os.path.abspath(doc_path)\n",
    "        doc = word.Documents.Open(abs_path)\n",
    "        paragraphs = [p.Range.Text.strip() for p in doc.Paragraphs if p.Range.Text.strip()]\n",
    "        return paragraphs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing .doc file with MS Word: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        if doc:\n",
    "            doc.Close(False) # Close the document without saving changes\n",
    "        if word:\n",
    "            word.Quit() # Quit the Word application\n",
    "\n",
    "doc_file = \"7Y6H93I4L6F5bcplrUpPbf5AjQcypbJfrevTSiNf.doc\"\n",
    "extract_paragraphs_from_doc(doc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4514c0a",
   "metadata": {},
   "source": [
    "## 2. docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41e381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading DOCX file s5NpVVwHUlH3SB7MbcSmcgkfuHK796YdA4F94ZQd.docx: Package not found at 's5NpVVwHUlH3SB7MbcSmcgkfuHK796YdA4F94ZQd.docx'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_paragraphs_from_docx(doc_path):\n",
    "    try:\n",
    "        doc = Document(doc_path); blocks = [p.text for p in doc.paragraphs if p.text.strip()]\n",
    "        for table in doc.tables:\n",
    "            for row in table.rows:\n",
    "                for cell in row.cells:\n",
    "                    if cell.text.strip(): blocks.append(cell.text)\n",
    "        return blocks\n",
    "    except Exception as e: print(f\"Error reading DOCX file {doc_path}: {e}\"); return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "docx_file2 = \"s5NpVVwHUlH3SB7MbcSmcgkfuHK796YdA4F94ZQd.docx\"\n",
    "extract_paragraphs_from_docx(docx_file2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b291d",
   "metadata": {},
   "source": [
    "## 3. pdf\n",
    "\n",
    "#### 3.1 without  reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c34ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate-based parsing failed: [Errno 2] No such file or directory: '0Fslu7lGZ8dJG0OYQGf1TgzFMPyFDEv0n5Q96BNq.pdf'. Attempting OCR...\n"
     ]
    }
   ],
   "source": [
    "def extract_paragraphs_from_pdf(pdf_path):\n",
    "    all_paragraphs = []\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                words = page.extract_words(keep_blank_chars=False)\n",
    "                if not words: continue\n",
    "                lines = {}\n",
    "                for word in words:\n",
    "                    line_top = round(word['top'], 2)\n",
    "                    if line_top not in lines: lines[line_top] = []\n",
    "                    lines[line_top].append(word)\n",
    "                for line_top in lines: lines[line_top].sort(key=lambda w: w['x0'])\n",
    "                sorted_lines = sorted(lines.items(), key=lambda item: item[0])\n",
    "                reconstructed_lines = []; line_heights = []; last_top = None\n",
    "                for top, words_in_line in sorted_lines:\n",
    "                    text = \" \".join(w['text'] for w in words_in_line)\n",
    "                    reconstructed_lines.append({'top': top, 'text': text})\n",
    "                    if last_top is not None: line_heights.append(top - last_top)\n",
    "                    last_top = top\n",
    "                if not reconstructed_lines: continue\n",
    "                avg_line_height = sum(line_heights) / len(line_heights) if line_heights else 12\n",
    "                paragraph_break_threshold = avg_line_height * 1.5\n",
    "                current_paragraph = reconstructed_lines[0]['text']\n",
    "                for i in range(1, len(reconstructed_lines)):\n",
    "                    prev_line, curr_line = reconstructed_lines[i-1], reconstructed_lines[i]\n",
    "                    if (curr_line['top'] - prev_line['top']) > paragraph_break_threshold:\n",
    "                        all_paragraphs.append(current_paragraph)\n",
    "                        current_paragraph = curr_line['text']\n",
    "                    else:\n",
    "                        current_paragraph += \" \" + curr_line['text']\n",
    "                all_paragraphs.append(current_paragraph)\n",
    "        if all_paragraphs: print(\"Successfully extracted paragraphs using coordinate-based method.\"); return all_paragraphs\n",
    "        print(\"Coordinate-based method failed. Attempting OCR...\")\n",
    "    except Exception as e: print(f\"Coordinate-based parsing failed: {e}. Attempting OCR...\")\n",
    "\n",
    "pdf_file = \"0Fslu7lGZ8dJG0OYQGf1TgzFMPyFDEv0n5Q96BNq.pdf\" \n",
    "extract_paragraphs_from_pdf(pdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b16070",
   "metadata": {},
   "source": [
    "#### 3.2 with reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdf5a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate-based parsing failed: [Errno 2] No such file or directory: '0Fslu7lGZ8dJG0OYQGf1TgzFMPyFDEv0n5Q96BNq.pdf'. Attempting OCR...\n"
     ]
    }
   ],
   "source": [
    "def _reconstruct_paragraphs_from_page(page):\n",
    "    \"\"\"Helper function to reconstruct paragraphs on a single page using coordinates.\"\"\"\n",
    "    words = page.extract_words(keep_blank_chars=False, x_tolerance=2)\n",
    "    if not words: return []\n",
    "    lines = {};\n",
    "    for word in words:\n",
    "        line_top = round(word['top'], 2)\n",
    "        if line_top not in lines: lines[line_top] = []\n",
    "        lines[line_top].append(word)\n",
    "    for line_top in lines: lines[line_top].sort(key=lambda w: w['x0'])\n",
    "    sorted_lines = sorted(lines.items(), key=lambda item: item[0])\n",
    "    reconstructed_lines = []; line_heights = []; last_top = None\n",
    "    for top, words_in_line in sorted_lines:\n",
    "        text = \" \".join(w['text'] for w in words_in_line)\n",
    "        reconstructed_lines.append({'top': top, 'text': text})\n",
    "        if last_top is not None: line_heights.append(top - last_top)\n",
    "        last_top = top\n",
    "    if not reconstructed_lines: return []\n",
    "    avg_line_height = sum(line_heights) / len(line_heights) if line_heights else 12\n",
    "    paragraph_break_threshold = avg_line_height * 1.5\n",
    "    page_paragraphs = []; current_paragraph = reconstructed_lines[0]['text']\n",
    "    for i in range(1, len(reconstructed_lines)):\n",
    "        prev_line, curr_line = reconstructed_lines[i-1], reconstructed_lines[i]\n",
    "        if (curr_line['top'] - prev_line['top']) > paragraph_break_threshold:\n",
    "            page_paragraphs.append(current_paragraph)\n",
    "            current_paragraph = curr_line['text']\n",
    "        else:\n",
    "            current_paragraph += \" \" + curr_line['text']\n",
    "    page_paragraphs.append(current_paragraph)\n",
    "    return page_paragraphs\n",
    "\n",
    "def extract_paragraphs_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    FINAL PDF METHOD: Uses coordinate geometry and cross-page stitching\n",
    "    to perfectly reconstruct all paragraphs, even those split across pages.\n",
    "    \"\"\"\n",
    "    all_paragraphs = []\n",
    "    carry_over_paragraph = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                paragraphs_on_page = _reconstruct_paragraphs_from_page(page)\n",
    "                if not paragraphs_on_page: continue\n",
    "\n",
    "                # If there's a carry-over from the previous page, stitch it to the first paragraph\n",
    "                if carry_over_paragraph:\n",
    "                    paragraphs_on_page[0] = carry_over_paragraph + \" \" + paragraphs_on_page[0]\n",
    "                    carry_over_paragraph = \"\"\n",
    "\n",
    "                # Check if the last paragraph on THIS page is incomplete\n",
    "                last_para = paragraphs_on_page[-1]\n",
    "                # A simple but effective heuristic: if it doesn't end with punctuation, it's likely incomplete.\n",
    "                if not last_para.strip().endswith(('.', '?', '!', '\"', \"'\", ')', ':', ';')):\n",
    "                    carry_over_paragraph = paragraphs_on_page.pop()\n",
    "\n",
    "                all_paragraphs.extend(paragraphs_on_page)\n",
    "        \n",
    "        # Add any final carry-over from the very last page\n",
    "        if carry_over_paragraph:\n",
    "            all_paragraphs.append(carry_over_paragraph)\n",
    "\n",
    "        if all_paragraphs: print(\"Successfully extracted paragraphs using coordinate-based method.\"); return all_paragraphs\n",
    "        print(\"Coordinate-based method failed. Attempting OCR as last resort...\")\n",
    "    except Exception as e: print(f\"Coordinate-based parsing failed: {e}. Attempting OCR...\")\n",
    "\n",
    "\n",
    "pdf_file = \"0Fslu7lGZ8dJG0OYQGf1TgzFMPyFDEv0n5Q96BNq.pdf\" \n",
    "extract_paragraphs_from_pdf(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd22242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
