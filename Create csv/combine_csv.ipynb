{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92893bcc",
   "metadata": {},
   "source": [
    "### 1. Combine 15 parts into a large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3add94e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined CSV saved to: Policy text\\all_syllabus_summary_combined_1.csv\n",
      "✅ Combined CSV saved to: Policy text\\all_syllabus_summary_combined_2.csv\n",
      "✅ Combined CSV saved to: Policy text\\all_syllabus_summary_combined_3.csv\n",
      "✅ Combined CSV saved to: Policy text\\all_syllabus_summary_combined_4.csv\n",
      "✅ Combined CSV saved to: Policy text\\all_syllabus_summary_combined_5.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "base_dir = 'Policy text'\n",
    "\n",
    "for j in range(1, 6):\n",
    "    all_dfs = []\n",
    "    for i in range(1, 16):\n",
    "        folder_name = f'part {i}'\n",
    "        csv_path = os.path.join(base_dir, folder_name, f'syllabus_summary_{j}.csv')\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            all_dfs.append(df)\n",
    "        else:\n",
    "            print(f\"CSV not found: {csv_path}\")\n",
    "\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    output_path = os.path.join(base_dir, f'all_syllabus_summary_combined_{j}.csv')\n",
    "    combined_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"✅ Combined CSV saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08233b",
   "metadata": {},
   "source": [
    "### 2. Create a final file by finding the most frequent sentences in 5 attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d42eb1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean final CSV saved to: Policy text\\final_syllabus_summary.csv \n"
     ]
    }
   ],
   "source": [
    "base_dir = 'Policy text'\n",
    "dfs = []\n",
    "for i in range(1, 6):\n",
    "    path = os.path.join(base_dir, f'all_syllabus_summary_combined_{i}.csv')\n",
    "    df = pd.read_csv(path)\n",
    "    df['OriginalIndex'] = range(len(df))\n",
    "    df['Version'] = i  \n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "all_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "sort_key = dfs[0][['File', 'OriginalIndex']].copy()\n",
    "sort_key = sort_key.set_index('File')['OriginalIndex'].to_dict()\n",
    "\n",
    "final_rows = []\n",
    "\n",
    "grouped = all_df.groupby('File', sort=False)\n",
    "for file_name, group in grouped:\n",
    "    mode_values = group['AI Policy'].mode()\n",
    "    if not mode_values.empty:\n",
    "        policy_mode = mode_values.iloc[0]\n",
    "        matched_row = group[group['AI Policy'] == policy_mode].iloc[0]\n",
    "    else:\n",
    "        matched_row = group.iloc[0]\n",
    "    final_rows.append(matched_row)\n",
    "\n",
    "\n",
    "final_df = pd.DataFrame(final_rows)\n",
    "\n",
    "\n",
    "final_df['OriginalIndex'] = final_df['File'].map(sort_key)\n",
    "final_df = final_df.sort_values('OriginalIndex').drop(columns=['OriginalIndex', 'Version']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "final_path = os.path.join(base_dir, 'final_syllabus_summary.csv')\n",
    "final_df.to_csv(final_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"✅ Clean final CSV saved to: {final_path} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afd9e0",
   "metadata": {},
   "source": [
    "### 3. Rough analysis and estimation of the amount of manual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef446b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the amount of files that LLM fails: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('the amount of files that LLM fails: ')\n",
    "sum(final_df['LLM Failure']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae304a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing course code by the rule-based method: \n",
      "136\n"
     ]
    }
   ],
   "source": [
    "# Missing course code in the csv, 'all_syllabus_summary_combined_5.csv' \n",
    "# Note that all_syllabus_summary 1, 3, 4, 5 share the same rule to find the code, while all_syllabus_summary 2 use the other method.\n",
    "\n",
    "print('The missing course code by the rule-based method: ')\n",
    "print(sum(combined_df['Course Code'].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f9045c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Course Code</th>\n",
       "      <th>Department</th>\n",
       "      <th>Knowledge Area</th>\n",
       "      <th>AI Policy</th>\n",
       "      <th>Multiple Clusters</th>\n",
       "      <th>LLM Failure</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0CBWL9I53UwogXerQPA4BcTiQgsYcVe4Xw2R5rkY.pdf</td>\n",
       "      <td>FREN 0600</td>\n",
       "      <td>French Studies</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>For assignments written in French, students mu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0DLS8eklpSbyHbkZaAufNWlB0AQVFSdVkAFj8Aow.docx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>\"An assignment copied or barely reworded from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0LSAzakbpaLaUfLtCtUChU585hVxizgRmfnEQXWH.pdf</td>\n",
       "      <td>PHP 1501</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>Students may not use ChatGPT tools to complete...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0qzo0y6addAXK6uOmXpRgE9SInxWjyHtsfuspKbA.pdf</td>\n",
       "      <td>POLS 1225</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>Plagiarism violates the academic policies of B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1wfQsKPNkMjjw649KJk7Acf4nnKO72QOaBmYbzah.pdf</td>\n",
       "      <td>LITR 0100A</td>\n",
       "      <td>Literary Arts</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Additionally, no AI-generated work of any sort...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>zaOs0k980PB8UdwnQyKLmkM0O3OnveyIZeG2t7y3.pdf</td>\n",
       "      <td>MPA 2229</td>\n",
       "      <td>Watson Institute</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>zCw7quGJK5H1ioLe8zWbZOL0ppUgwS2XXpMSdKC1.pdf</td>\n",
       "      <td>TAPS 1500S</td>\n",
       "      <td>Theatre Arts and Performance Studies</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Any information gathered from AI tools should ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>zh2CCBO6bcV6UNGbIQ1OryyI8VjOnHcestbLDkW1.docx</td>\n",
       "      <td>ARTS 2003</td>\n",
       "      <td>Brown Arts Institute</td>\n",
       "      <td>Arts</td>\n",
       "      <td>With the advent of AI, a host of questions evo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>zKluYL45YMqrZOkBoUtxQh6DvaWOjv9oU9sJvfGO.pdf</td>\n",
       "      <td>POLS 2000</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>zLHd4QbRv0Nd7mfXQrdKCHBx21LwklGXlHDL2NIW.pdf</td>\n",
       "      <td>PHP 2506</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>One of the main objectives of this course is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               File Course Code  \\\n",
       "6      0CBWL9I53UwogXerQPA4BcTiQgsYcVe4Xw2R5rkY.pdf   FREN 0600   \n",
       "8     0DLS8eklpSbyHbkZaAufNWlB0AQVFSdVkAFj8Aow.docx         NaN   \n",
       "13     0LSAzakbpaLaUfLtCtUChU585hVxizgRmfnEQXWH.pdf    PHP 1501   \n",
       "22     0qzo0y6addAXK6uOmXpRgE9SInxWjyHtsfuspKbA.pdf   POLS 1225   \n",
       "46     1wfQsKPNkMjjw649KJk7Acf4nnKO72QOaBmYbzah.pdf  LITR 0100A   \n",
       "...                                             ...         ...   \n",
       "1457   zaOs0k980PB8UdwnQyKLmkM0O3OnveyIZeG2t7y3.pdf    MPA 2229   \n",
       "1464   zCw7quGJK5H1ioLe8zWbZOL0ppUgwS2XXpMSdKC1.pdf  TAPS 1500S   \n",
       "1468  zh2CCBO6bcV6UNGbIQ1OryyI8VjOnHcestbLDkW1.docx   ARTS 2003   \n",
       "1471   zKluYL45YMqrZOkBoUtxQh6DvaWOjv9oU9sJvfGO.pdf   POLS 2000   \n",
       "1473   zLHd4QbRv0Nd7mfXQrdKCHBx21LwklGXlHDL2NIW.pdf    PHP 2506   \n",
       "\n",
       "                                Department   Knowledge Area  \\\n",
       "6                           French Studies       Humanities   \n",
       "8                                  Unknown          Unknown   \n",
       "13                           Public Health    Life Sciences   \n",
       "22                       Political Science  Social Sciences   \n",
       "46                           Literary Arts       Humanities   \n",
       "...                                    ...              ...   \n",
       "1457                      Watson Institute  Social Sciences   \n",
       "1464  Theatre Arts and Performance Studies       Humanities   \n",
       "1468                  Brown Arts Institute             Arts   \n",
       "1471                     Political Science  Social Sciences   \n",
       "1473                         Public Health    Life Sciences   \n",
       "\n",
       "                                              AI Policy  Multiple Clusters  \\\n",
       "6     For assignments written in French, students mu...                  0   \n",
       "8     \"An assignment copied or barely reworded from ...                  0   \n",
       "13    Students may not use ChatGPT tools to complete...                  0   \n",
       "22    Plagiarism violates the academic policies of B...                  0   \n",
       "46    Additionally, no AI-generated work of any sort...                  0   \n",
       "...                                                 ...                ...   \n",
       "1457                                                and                  1   \n",
       "1464  Any information gathered from AI tools should ...                  1   \n",
       "1468  With the advent of AI, a host of questions evo...                  0   \n",
       "1471                                                and                  1   \n",
       "1473  One of the main objectives of this course is t...                  0   \n",
       "\n",
       "      LLM Failure  word_count  \n",
       "6               0          25  \n",
       "8               0          26  \n",
       "13              0          30  \n",
       "22              0          38  \n",
       "46              0          28  \n",
       "...           ...         ...  \n",
       "1457            0           1  \n",
       "1464            0          17  \n",
       "1468            0          34  \n",
       "1471            0           1  \n",
       "1473            0          42  \n",
       "\n",
       "[186 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text containing fewer than 50 words that needs to be checked.\n",
    "final_df['word_count'] = final_df['AI Policy'].fillna('').str.split().str.len()\n",
    "final_df[(final_df['word_count'] > 0) & (final_df['word_count'] < 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8099e54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of different codes obtained by the two methods:  43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Code_df1</th>\n",
       "      <th>Course Code_df2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PHP 121</td>\n",
       "      <td>PHP 0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HIST 199</td>\n",
       "      <td>HI 1956A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PHYS 2340</td>\n",
       "      <td>PHYS 2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>PHYS 1530</td>\n",
       "      <td>PHYS 2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ECON 136</td>\n",
       "      <td>POLS 1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>BIOL 2000X</td>\n",
       "      <td>BIOL 2000C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>HISP 232</td>\n",
       "      <td>HS 2030B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>PHP 121</td>\n",
       "      <td>PHP 2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>NEUR 2021</td>\n",
       "      <td>BIOL 1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>EDUC 164</td>\n",
       "      <td>EDUC 2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>MUSC 200</td>\n",
       "      <td>MU 200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>ECON 2020</td>\n",
       "      <td>IAPA 1700R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>PHP 121</td>\n",
       "      <td>PHP 2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>PHP 121</td>\n",
       "      <td>PHP 2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>LITR 209</td>\n",
       "      <td>LITR 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>HIAA 434</td>\n",
       "      <td>HIAA 0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>HIAA 434</td>\n",
       "      <td>HIAA 0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>PHP 121</td>\n",
       "      <td>PHP 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>NEUR 2021</td>\n",
       "      <td>BIOL 1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>IAPA 111</td>\n",
       "      <td>PHP 1802S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>CLAS 978</td>\n",
       "      <td>CLAS 0210T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>PHYS 0720</td>\n",
       "      <td>PHYS 0720/1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>TKSH 0100</td>\n",
       "      <td>TKSH 0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>LANG 195</td>\n",
       "      <td>HNDI 1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>PHP 121</td>\n",
       "      <td>PHP 2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>CLAS 104</td>\n",
       "      <td>CLAS 0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>ANTH 104</td>\n",
       "      <td>ANTH 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>PHYS 0720</td>\n",
       "      <td>PHYS 0720/1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>PHYS 0050</td>\n",
       "      <td>PHYS 0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>CLAS 1225</td>\n",
       "      <td>HIST 1200C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>PHYS 2410</td>\n",
       "      <td>PHYS 2420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>ARAB 434</td>\n",
       "      <td>ARAB 0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>ITAL 100</td>\n",
       "      <td>ITAL 0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>ENGN 182</td>\n",
       "      <td>ENGN 1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>LMM 128</td>\n",
       "      <td>BIOL 1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>BIOL 2021</td>\n",
       "      <td>PHP 0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>SOC 125</td>\n",
       "      <td>IAPA 1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>ECON 2012</td>\n",
       "      <td>EC 2860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>PHIL 105</td>\n",
       "      <td>PHIL 2140I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>SOC 102</td>\n",
       "      <td>SOC 2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>MATH 121</td>\n",
       "      <td>MATH 0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>CLAS 1225</td>\n",
       "      <td>HIST 1200C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>ECON 128</td>\n",
       "      <td>ECON 2840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Course Code_df1 Course Code_df2\n",
       "25           PHP 121        PHP 0850\n",
       "28          HIST 199        HI 1956A\n",
       "42         PHYS 2340       PHYS 2030\n",
       "63         PHYS 1530       PHYS 2050\n",
       "102         ECON 136       POLS 1440\n",
       "199       BIOL 2000X      BIOL 2000C\n",
       "201         HISP 232        HS 2030B\n",
       "231          PHP 121        PHP 2950\n",
       "271        NEUR 2021       BIOL 1865\n",
       "324         EDUC 164       EDUC 2380\n",
       "325         MUSC 200          MU 200\n",
       "459        ECON 2020      IAPA 1700R\n",
       "476          PHP 121        PHP 2480\n",
       "521          PHP 121        PHP 2180\n",
       "522         LITR 209       LITR 1200\n",
       "527         HIAA 434       HIAA 0140\n",
       "619         HIAA 434       HIAA 0100\n",
       "637          PHP 121        PHP 2015\n",
       "680        NEUR 2021       BIOL 1865\n",
       "687         IAPA 111       PHP 1802S\n",
       "718         CLAS 978      CLAS 0210T\n",
       "744        PHYS 0720  PHYS 0720/1720\n",
       "769        TKSH 0100       TKSH 0200\n",
       "771         LANG 195       HNDI 1080\n",
       "832          PHP 121        PHP 2150\n",
       "839         CLAS 104       CLAS 0450\n",
       "873         ANTH 104        ANTH 100\n",
       "932        PHYS 0720  PHYS 0720/1720\n",
       "981        PHYS 0050       PHYS 0160\n",
       "987        CLAS 1225      HIST 1200C\n",
       "1027       PHYS 2410       PHYS 2420\n",
       "1041        ARAB 434       ARAB 0100\n",
       "1168        ITAL 100       ITAL 0200\n",
       "1176        ENGN 182       ENGN 1140\n",
       "1225         LMM 128       BIOL 1270\n",
       "1250       BIOL 2021        PHP 0720\n",
       "1277         SOC 125       IAPA 1001\n",
       "1308       ECON 2012         EC 2860\n",
       "1366        PHIL 105      PHIL 2140I\n",
       "1385         SOC 102        SOC 2040\n",
       "1404        MATH 121       MATH 0750\n",
       "1430       CLAS 1225      HIST 1200C\n",
       "1435        ECON 128       ECON 2840"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Different course code counts yielded by two methods \n",
    "all_dfs = []\n",
    "for i in range(1, 16):\n",
    "    folder_name = f'part {i}'\n",
    "    csv_path = os.path.join(base_dir, folder_name, 'syllabus_summary_2.csv')\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        all_dfs.append(df)\n",
    "    else:\n",
    "        print(f\"CSV not found: {csv_path}\")\n",
    "\n",
    "combined_df_2 = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "merged = pd.merge(combined_df,combined_df_2, on='File', suffixes=('_df1', '_df2'))\n",
    "\n",
    "mismatches = merged[merged['Course Code_df1'] != merged['Course Code_df2']]\n",
    "mismatches_code = mismatches[mismatches['Course Code_df1'].notna()][['Course Code_df1', 'Course Code_df2']] \n",
    "print('The number of different codes obtained by the two methods: ', len(mismatches_code) )\n",
    "mismatches_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
